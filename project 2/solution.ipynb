{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, log_loss\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine(as_frame=True)\n",
    "X,Y = data.data,data.target\n",
    "nfeats = len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only classes 0 and 1\n",
    "X = X[(Y==0) | (Y==1)].reset_index(drop=True)\n",
    "Y = Y[(Y==0) | (Y==1)].reset_index(drop=True).values\n",
    "Y[Y==0]=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, y, weights):\n",
    "    return np.sum(np.log(1 + np.exp(-y * (x.dot(weights)))))\n",
    "\n",
    "def grad_update(\n",
    "    x, y, weights, feats_selection=[], mode=\"all\", learn_rate=0.1, curr_coord=0\n",
    "):\n",
    "    assert weights.shape == (nfeats + 1, 1)\n",
    "\n",
    "    if x.shape != (nfeats + 1, 1) and mode != \"all\":\n",
    "        x = x.reshape([-1, 1])\n",
    "\n",
    "    if mode == \"all\":\n",
    "        gradient = -np.sum((y * x) / (1 + np.exp(y * (x.dot(weights)))), 0).reshape(\n",
    "            [-1, 1]\n",
    "        )\n",
    "    else:\n",
    "        gradient = -(y * x) / (1 + np.exp(y * (weights.T.dot(x)))).reshape([-1, 1])\n",
    "\n",
    "    if feats_selection == \"random\":\n",
    "        temp = np.zeros(gradient.shape)\n",
    "        random_coord = np.random.choice(14)\n",
    "        temp[random_coord] = gradient[random_coord]\n",
    "        gradient = temp\n",
    "\n",
    "    elif feats_selection == \"max\":\n",
    "        t = np.argmax(abs(gradient))\n",
    "        gradient[gradient != gradient[t]] = 0\n",
    "\n",
    "    elif feats_selection == \"round_robin\":\n",
    "        temp = np.zeros(gradient.shape)\n",
    "        temp[curr_coord] = gradient[curr_coord]\n",
    "        gradient = temp\n",
    "\n",
    "    return weights - (learn_rate * gradient.reshape([-1, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :: Current Loss: 10.77 :: 89.38 :: 33.05 :: 253.11\n",
      "Epoch 499 :: Current Loss: 0.08 :: 0.75 :: 0.35 :: 0.67\n"
     ]
    }
   ],
   "source": [
    "runs = 100\n",
    "nfeats = len(X.columns)\n",
    "epochs = 500\n",
    "fin_loss = []\n",
    "\n",
    "for i in range(runs):\n",
    "    curr_coord = 1\n",
    "    fig = go.Figure()\n",
    "\n",
    "    X_train, y_train = X.copy(), Y.copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_train = np.append(X_train, np.ones([len(X_train), 1]), 1)\n",
    "    y_train = y_train.reshape([-1, 1])\n",
    "\n",
    "    weights = np.random.random([nfeats + 1, 1])\n",
    "    weightsRandomUpdate = weights.copy()\n",
    "    weightsMaxGradUpdate = weights.copy()\n",
    "    weightsRR = weights.copy()\n",
    "\n",
    "    loss = []\n",
    "    lossMaxGradUpdate = []\n",
    "    lossRandomUpdate = []\n",
    "    lossRR = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for it in range(len(X_train)):\n",
    "\n",
    "            # All weights update\n",
    "            weights = grad_update(X_train[it], y_train[it], weights, mode=\"stochastic\")\n",
    "            curr_loss = loss_func(X_train, y_train, weights)\n",
    "\n",
    "            # Random weights update\n",
    "            weightsRandomUpdate = grad_update(\n",
    "                X_train[it],\n",
    "                y_train[it],\n",
    "                weightsRandomUpdate,\n",
    "                feats_selection=\"random\",\n",
    "                mode=\"stochastic\",\n",
    "            )\n",
    "            curr_loss_rand_update = loss_func(X_train, y_train, weightsRandomUpdate)\n",
    "\n",
    "            # Only Maximum Gradient Weight Update\n",
    "            weightsMaxGradUpdate = grad_update(\n",
    "                X_train[it],\n",
    "                y_train[it],\n",
    "                weightsMaxGradUpdate,\n",
    "                feats_selection=\"max\",\n",
    "                mode=\"stochastic\",\n",
    "            )\n",
    "            curr_loss_max_grad = loss_func(X_train, y_train, weightsMaxGradUpdate)\n",
    "\n",
    "            # Round Robin Weight Update\n",
    "            weightsRR = grad_update(\n",
    "                X_train[it],\n",
    "                y_train[it],\n",
    "                weightsRR,\n",
    "                mode=\"stochastic\",\n",
    "                feats_selection=\"round_robin\",\n",
    "                curr_coord=curr_coord,\n",
    "            )\n",
    "            curr_loss_rr = loss_func(X_train, y_train, weightsRR)\n",
    "\n",
    "        curr_coord = (curr_coord + 1) % (nfeats + 1)\n",
    "\n",
    "        loss.append(curr_loss)\n",
    "        lossRandomUpdate.append(curr_loss_rand_update)\n",
    "        lossMaxGradUpdate.append(curr_loss_max_grad)\n",
    "        lossRR.append(curr_loss_rr)\n",
    "\n",
    "        if e % 499 == 0 and i==0:\n",
    "            print(\n",
    "                f\"Epoch {e} :: Current Loss: {curr_loss:0.2f} :: {curr_loss_rand_update:0.2f} :: {curr_loss_max_grad:0.2f} :: {curr_loss_rr:0.2f}\"\n",
    "            )\n",
    "\n",
    "    fin_loss.append(\n",
    "        (curr_loss, curr_loss_rand_update, curr_loss_max_grad, curr_loss_rr)\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(epochs)), y=loss, mode=\"lines\", name=f\"All Weights Update\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(epochs)),\n",
    "            y=lossRandomUpdate,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Random Weights Update\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(epochs)),\n",
    "            y=lossMaxGradUpdate,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Max Gradient Weight Update\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(epochs)),\n",
    "            y=lossRR,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Round Robin Weight Update\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    legend=dict(yanchor=\"top\", y=0.98, xanchor=\"right\", x=0.99),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Epoch\", title_standoff=5)\n",
    "fig.update_yaxes(title_text=\"Loss  (log-scale)\", title_standoff=5,type=\"log\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Loss Graphs \n",
    "leg = [\"All\",\"Random\",\"Max Gradient\",\"Round Robin\"]\n",
    "\n",
    "df=pd.DataFrame(fin_loss)\n",
    "df.columns=leg\n",
    "df=df.reset_index()\n",
    "df=pd.melt(df,id_vars=[\"index\"],value_vars=leg)\n",
    "df=df.rename(columns={\"value\":\"Final Loss\",\"index\":\"#Runs\",\"variable\":\"Weight Update Strategies\"})\n",
    "\n",
    "# Final Loss vs No. of Runs Plot\n",
    "fig=px.line(df,x=\"#Runs\",y=\"Final Loss\",color=\"Weight Update Strategies\",height=600,width=800)\n",
    "fig.update_layout(legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.02,\n",
    "    xanchor=\"right\",\n",
    "    x=1\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Loss Distribution Plot\n",
    "fig = px.histogram(df,x=\"Final Loss\",color=\"Weight Update Strategies\",height=500,width=800,nbins=50,barmode=\"overlay\",marginal=\"box\")\n",
    "fig.update_layout(legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.02,\n",
    "    xanchor=\"right\",\n",
    "    x=1\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Final Loss (with 95% confidence interval): \")\n",
    "for i,l in enumerate(leg):\n",
    "    print(f\"{l} Weight Update Strategy: \\n {np.mean(fin_loss,0)[i]:0.2f} +- {2*np.std(fin_loss,0)[i]:0.2f}   \")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "751573683e24ccd8408e30aa08d302f09a2e3ffe5490b3abaa025a17d3d9d43c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
